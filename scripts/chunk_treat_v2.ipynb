{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad7045c7",
   "metadata": {},
   "source": [
    "# Voyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8710ed3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import regex as re\n",
    "\n",
    "from typing import Dict\n",
    "\n",
    "# Pega o diretório atual do notebook\n",
    "notebook_dir = os.getcwd() # ou os.path.dirname(__file__) se fosse um script .py\n",
    "\n",
    "# Assume que 'src' está no mesmo nível do notebook ou um nível acima\n",
    "# Ajuste '..' conforme a estrutura do seu projeto\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, '..')) # Volta um diretório\n",
    "\n",
    "# Se o 'src' estiver diretamente no mesmo nível do notebook:\n",
    "# project_root = notebook_dir\n",
    "\n",
    "# Adiciona o diretório raiz do projeto ao sys.path\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d36a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.interact_database_sql import get_all_days_content\n",
    "from src.voyage_emb import get_voyage_embeddings, voyage_rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05d40bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Recuperar apenas content_without_image e content_image_described para todos os registros\n",
    "results = get_all_days_content(fields=['content_without_image', 'content_image_described'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bbf1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = [result['content_image_described'] if result['content_image_described'] != \"\" else result['content_without_image'] for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcf61ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53edd1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First import the chunker you want from Chonkie\n",
    "from chonkie import SemanticChunker, RecursiveChunker\n",
    "\n",
    "# Initialize the chunker\n",
    "# chunker = RecursiveChunker()\n",
    "chunker = SemanticChunker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b53de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = []\n",
    "for day in content:\n",
    "    # Chunk some text\n",
    "    _chunks = chunker(day)\n",
    "\n",
    "    # Access chunks\n",
    "    for chunk in _chunks:\n",
    "        #print(f\"Chunk: {chunk.text}\")\n",
    "        chunks.append(chunk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e0f151",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_size = 0\n",
    "for chunk in chunks:\n",
    "    new_size = len(chunk)\n",
    "    if new_size > old_size:\n",
    "        max_size = new_size\n",
    "    else:\n",
    "        max_size = old_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7456bbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca6a1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_emb: list[dict] = [{'chunk': chunk, 'embedding': ''} for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cfb2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_emb[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d2841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make embeddings\n",
    "for chunk in chunks_emb:\n",
    "    # Get the chunk text to encode\n",
    "    chunk_text = chunk['chunk']\n",
    "    # Generate the embedding for this specific chunk\n",
    "    # Note: model.encode usually takes a list of strings, even for a single string,\n",
    "    # and returns a list of embeddings. So, we get the first (and only) embedding.\n",
    "    \n",
    "    # Model2Vec\n",
    "    # embedding = model.encode(chunk_text)\n",
    "    \n",
    "    # Voyage\n",
    "    embedding = get_voyage_embeddings(chunk_text)\n",
    "    time.sleep(0.05)\n",
    "    # Assign the generated embedding to the 'embedding' key\n",
    "    chunk['embedding'] = embedding\n",
    "    \n",
    "\n",
    "# # Make sequences of token embeddings\n",
    "# token_embeddings = model.encode_as_sequence([\"It's dangerous to go alone!\", \"It's a secret to everybody.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "38d9557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(vec1: np.ndarray, vec2: np.ndarray) -> float:\n",
    "    \"\"\"Calcula a similaridade de cosseno entre dois vetores.\"\"\"\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    \n",
    "    if norm_vec1 == 0 or norm_vec2 == 0:\n",
    "        return 0.0 # Evita divisão por zero\n",
    "        \n",
    "    return dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "def semantic_search(query: str, indexed_chunks: list[dict], model = None, k = 10) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Realiza uma pesquisa de similaridade semântica.\n",
    "\n",
    "    Args:\n",
    "        query (str): A string de consulta.\n",
    "        indexed_chunks (list[dict]): A lista de dicionários de chunks com embeddings.\n",
    "        model: O modelo usado para gerar embeddings.\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: Uma lista de dicionários de chunks, ordenados por similaridade\n",
    "                    (maior primeiro), incluindo a pontuação de similaridade.\n",
    "    \"\"\"\n",
    "    # 1. Gerar o embedding da consulta\n",
    "    query_embedding = get_voyage_embeddings(query)\n",
    "    #print(f\"\\nEmbedding da Consulta ('{query}'): {query_embedding}\")\n",
    "\n",
    "    results = []\n",
    "    # 2. Calcular similaridade para cada chunk\n",
    "    for item in indexed_chunks:\n",
    "        chunk_text = item['chunk']\n",
    "        chunk_embedding = item['embedding']\n",
    "        \n",
    "        # Certifique-se de que o embedding do chunk também é um array numpy\n",
    "        # (se o seu modelo já retorna numpy arrays, isso pode ser redundante)\n",
    "        if not isinstance(chunk_embedding, np.ndarray):\n",
    "             chunk_embedding = np.array(chunk_embedding)\n",
    "\n",
    "        similarity = calculate_cosine_similarity(query_embedding, chunk_embedding)\n",
    "        \n",
    "        results.append({\n",
    "            'chunk': chunk_text,\n",
    "            'similarity': similarity,\n",
    "            'embedding': chunk_embedding # Opcional, para debug\n",
    "        })\n",
    "    \n",
    "    # 3. Ordenar os resultados pela similaridade (decrescente)\n",
    "    results.sort(key=lambda x: x['similarity'], reverse=True)\n",
    "    \n",
    "    return results[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ead0e0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inicializa o cliente Gemini API ---\n",
    "from src.classe_gemini import GeminiApiClient\n",
    "# Certifique-se de que a variável de ambiente 'GOOGLE_API_KEY' está definida com sua chave de API\n",
    "try:\n",
    "    api_key = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise ValueError(\"A variável de ambiente 'GOOGLE_API_KEY' não está definida.\")\n",
    "    \n",
    "    gemini_client = GeminiApiClient(api_key=api_key)\n",
    "except ValueError as e:\n",
    "    print(f\"Erro de configuração da API: {e}\")\n",
    "    exit() # Encerra o programa se a chave da API não estiver configurada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1a62515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = r\"C:\\Users\\fuedj\\Documents\\Code\\RAG_Dr_Voss_v2\\drvossv2\\data\\unit_qa.json\"\n",
    "\n",
    "with open(json_file, mode='r', encoding='utf-8') as jf:\n",
    "    jsonfile: Dict = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e12872b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonfile = {\"How does the doctor look like?\":\"Hair\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d895b1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************\n",
      "Query: How does the doctor look like?\n",
      "Gemini: Voss is fair-skinned with auburn hair styled in a soft wave.\n",
      "\n",
      "Actual Answer: Hair\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "answers_dict = []\n",
    "k = 30\n",
    "\n",
    "for query, answer in jsonfile.items():\n",
    "    reranked = []\n",
    "    \n",
    "    search_results = semantic_search(query, chunks_emb, k=k)\n",
    "    txt_results = []\n",
    "    \n",
    "    for chunk in search_results:\n",
    "        txt_results.append(chunk['chunk'])\n",
    "    \n",
    "    sorted_rows = voyage_rerank(\n",
    "        query=query,\n",
    "        documents=txt_results[:k]\n",
    "        )    \n",
    "    \n",
    "    top_3 = sorted_rows[:10]  # Já está ordenado por relevance_score (maior para menor)\n",
    "    \n",
    "    # Extrair apenas o texto dos documentos\n",
    "    top_3_texto = [doc for doc, score, index in top_3]\n",
    "    \n",
    "    for i, doc in enumerate(top_3_texto, 1):\n",
    "        reranked.append(doc)\n",
    "        \n",
    "    # --- Chamada da API ---\n",
    "    \n",
    "    model_name = 'gemini-1.5-pro' # Ou 'gemini-1.5-pro' se preferir um modelo mais potente\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        You are answering a question from a fantasy world in a travel log journey of Doctor Voss, a woman visiting the capital of Veridia.\n",
    "        Question: {query}\n",
    "        Here is the context to help you answer: {reranked}.\n",
    "        Bring the answer **only**. Example: 'The Veridian's Skys were blue most days.'\n",
    "        If you don't know the answer, respond: 'NTD' - meaning nothing to disclosure.\n",
    "        If you are not sure, respond: 'NS' - meaning not sure.\n",
    "        \"\"\"\n",
    "        \n",
    "    prompt_parts = [\n",
    "        {\"text\": f\"{prompt}\"}\n",
    "    ]\n",
    "    # Chama o método da classe GeminiApiClient\n",
    "    response_data = gemini_client.generate_multimodal_content(model_name, prompt_parts)\n",
    "\n",
    "    # Extrai o texto da resposta usando o método da classe\n",
    "    generated_text = gemini_client.extract_text_from_response(response_data)\n",
    "\n",
    "    if generated_text:\n",
    "        print(f\"********************************\\nQuery: {query}\")\n",
    "        print(f\"Gemini: {generated_text}\")\n",
    "        print(f\"Actual Answer: {answer}\")\n",
    "        print(\"--------------------------------\")\n",
    "        \n",
    "        answers_dict.append({\n",
    "            'query': query,\n",
    "            'llm_answer': generated_text,\n",
    "            'actual_answer': answer\n",
    "        })\n",
    "    else:\n",
    "        print(\"\\nNão foi possível extrair texto da resposta do Gemini.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9b110961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"7th Day of Snowrest 1856 - Whispers of Yesteryears\\n\\nSpent today trailing the footprints of Veridia's storied past. An unexpected storm swept across the plains, its wind carrying dust and traces of history. As I sheltered in the attic amid relics of family estates, my fingers brushed past the cracked leather cover of an ancestor's journal. Within its pages were accounts of voyages across the continents, at a time when skies fled the fleet sails of Veridia's first airships.\\n\\nI found myself drawn into tales of their embroidered sails cutting through the thick ocean mist, guided by the quartz compasses of old. As the rain drummed a rhythm upon the roof, I read of the Unity Arc—a now-restored relic from a bygone era of architectural magnificence, once gracing the port city of Lyra Bay. How the world shifts and turns, yet in some ways, history circles back upon itself.\\n\\nThis storm seems a harbinger of change; a metaphor of sorts for the turbulence we must embrace to etch a future amongst the stars, guided by the legacy of wisdom left by those who came before.\\n\\nPicture - Dr. \",\n",
       " ' Small, arched doorways at their bases suggest hidden interiors. They stand on a low, rounded hill.\\n',\n",
       " \"13th Day of Moondusk 1856 - Northern Heights and Passing Whispers\\n\\nToday's journey took me away from the bustling heart of Dolverin and toward the rugged charm of Veridia's mountainous north. Here, in the embrace of towering peaks, every path opens up to the most stunning vistas and countless hiking trails. My guide for the day, a seasoned trekker named Arin, led me through one such trail, recounting its history with reverence. He spoke of intrepid explorers and whispered legends of past centuries, the kind that make the north seem alive with memory.\\n\\nAt a particularly breathtaking overlook, I paused, letting the cool air brush against my face. There's something immensely humbling about seeing the world stretched out before you, painted in hues of green and rocky greys, under an open sky. It reminds me of the broader spectrum of human experience—our achievements carved into the present landscape.\\n\\nPicture - Dr. \",\n",
       " '\\n####',\n",
       " ' She wears a teal wrap dress and a delicate necklace. Her gaze is focused on a large, open book before her. ',\n",
       " '\\nthin, contributes to its resplendence.\\n\\n##',\n",
       " 'Voss, fair-skinned with auburn hair styled in a soft wave, sits at a wooden desk by arched windows. ',\n",
       " \"5th Day of Snowrest 1856 - Shadows of Time\\n\\nEver since the gathering at the Celestial Pavilion, my thoughts have been preoccupied with the threads of our future. Today, as I sat by the hearth, embers crackling softly beneath the mantle of a chilling winter's eve, my mind wandered back to that fervent debate over Kyloria's proposal. I remember feeling an unexpected kinship with a Kylorian delegate during our spirited discussion over tea brewed with Veridian herbs—a delicate touch of saffron and korynth. Such moments remind me that understanding often blossoms amidst shared cups.\\n\\nPicture - Dr. \",\n",
       " 'Voss, perched on a rocky outcrop, plays a flute. ',\n",
       " '\\n\\nAs I made my way back to my lodgings, snow began to fall softly around me, each flake a secret\\n\\nmessage descending from the heavens. I paused, closing my eyes to the cold, and welcomed its cool kiss. ']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "478e94ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\fuedj\\Documents\\Code\\RAG_Dr_Voss_v2\\drvossv2\\data\\answers_dict.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(answers_dict, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
