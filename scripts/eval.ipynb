{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "49ac4252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import regex as re\n",
    "\n",
    "from typing import Dict\n",
    "\n",
    "# Pega o diretório atual do notebook\n",
    "notebook_dir = os.getcwd() # ou os.path.dirname(__file__) se fosse um script .py\n",
    "\n",
    "# Assume que 'src' está no mesmo nível do notebook ou um nível acima\n",
    "# Ajuste '..' conforme a estrutura do seu projeto\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, '..')) # Volta um diretório\n",
    "\n",
    "# Se o 'src' estiver diretamente no mesmo nível do notebook:\n",
    "# project_root = notebook_dir\n",
    "\n",
    "# Adiciona o diretório raiz do projeto ao sys.path\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7716e00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.classe_gemini import GeminiApiClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "42a17c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List, Dict\n",
    "import statistics\n",
    "\n",
    "# Suponha que gemini_client esteja definido com generate_multimodal_content e extract_text_from_response\n",
    "\n",
    "def evaluate_answers(\n",
    "    answers_dict: List[Dict[str, str]],\n",
    "    model_name: str = \"gemini-1.5-pro\"\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Avalia as respostas em answers_dict usando a API do Gemini para calcular similaridade semântica.\n",
    "\n",
    "    Args:\n",
    "        answers_dict (List[Dict[str, str]]): Lista de dicionários com 'query', 'llm_answer', 'actual_answer'.\n",
    "        gemini_client: Cliente da API Gemini com métodos generate_multimodal_content e extract_text_from_response.\n",
    "        model_name (str): Modelo Gemini a ser usado (padrão: 'gemini-1.5-pro').\n",
    "\n",
    "    Returns:\n",
    "        Dict: Resultados da avaliação, incluindo métricas e detalhes por query.\n",
    "    \"\"\"\n",
    "    \n",
    "        # --- Inicializa o cliente Gemini API ---\n",
    "    \n",
    "    try:\n",
    "        api_key = os.environ.get(\"GOOGLE_API_KEY\")\n",
    "        if not api_key:\n",
    "            raise ValueError(\"A variável de ambiente 'GOOGLE_API_KEY' não está definida.\")\n",
    "        \n",
    "        gemini_client = GeminiApiClient(api_key=api_key)\n",
    "    except ValueError as e:\n",
    "        print(f\"Erro de configuração da API: {e}\")\n",
    "        exit() # Encerra o programa se a chave da API não estiver configurada\n",
    "        \n",
    "    evaluation_results = {\n",
    "        \"evaluations\": [],\n",
    "        \"average_similarity\": 0.0,\n",
    "        \"exact_match_count\": 0,\n",
    "        \"total_queries\": len(answers_dict)\n",
    "    }\n",
    "    \n",
    "    for entry in answers_dict:\n",
    "        query = entry.get('query', '')\n",
    "        llm_answer = entry.get('llm_answer', '')\n",
    "        actual_answer = entry.get('actual_answer', '')\n",
    "\n",
    "        # Verificar acurácia exata (case-insensitive, ignorando espaços)\n",
    "        # is_exact_match = (\n",
    "        #     llm_answer.strip().lower() == actual_answer.strip().lower()\n",
    "        #     if llm_answer and actual_answer else False\n",
    "        # )\n",
    "        # if is_exact_match:\n",
    "        #     evaluation_results[\"exact_match_count\"] += 1\n",
    "\n",
    "        # Montar o prompt para o Gemini avaliar similaridade\n",
    "        \n",
    "        \n",
    "        system_prompt = f\"\"\"\n",
    "            You are an evaluator in a fantasy world context. Your task is to compare two answers to a question and provide a semantic similarity score between 0 and 1, where:\n",
    "            - 1 means the answers are semantically identical or convey the same meaning.\n",
    "            - 0 means the answers are completely different.\n",
    "            - Partial similarity should be scored between 0 and 1 (e.g., 0.8 for very similar answers with minor differences).\n",
    "\n",
    "            Input format:\n",
    "            - Question: {query}\n",
    "            - Generated Answer: {llm_answer}\n",
    "            - Expected Answer: {actual_answer}\n",
    "\n",
    "            Output format:\n",
    "            - Similarity Score: [number between 0 and 1]\n",
    "            - Explanation: [brief explanation of the similarity score]\n",
    "        \"\"\"\n",
    "\n",
    "        prompt = system_prompt\n",
    "\n",
    "        prompt_parts = [{\"text\": prompt}]\n",
    "\n",
    "        # Chamar a API do Gemini\n",
    "        try:\n",
    "            response_data = gemini_client.generate_multimodal_content(model_name, prompt_parts)\n",
    "            #print(response_data)\n",
    "            evaluation_text = gemini_client.extract_text_from_response(response_data)\n",
    "\n",
    "            # Extrair pontuação de similaridade e explicação\n",
    "            similarity_score = 0.0\n",
    "            explanation = \"No explanation provided.\"\n",
    "            if evaluation_text:\n",
    "                lines = evaluation_text.split('\\n')\n",
    "                for line in lines:\n",
    "                    if line.startswith(\"Similarity Score:\"):\n",
    "                        try:\n",
    "                            similarity_score = float(line.split(\":\")[1].strip())\n",
    "                        except (ValueError, IndexError):\n",
    "                            print(f\"Erro ao extrair pontuação para query: {query}\")\n",
    "                    elif line.startswith(\"Explanation:\"):\n",
    "                        explanation = line.split(\":\", 1)[1].strip()\n",
    "\n",
    "            evaluation_results[\"evaluations\"].append({\n",
    "                \"query\": query,\n",
    "                \"llm_answer\": llm_answer,\n",
    "                \"actual_answer\": actual_answer,\n",
    "                \"similarity_score\": similarity_score,\n",
    "                \"explanation\": explanation\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao avaliar query '{query}': {e}\")\n",
    "            evaluation_results[\"evaluations\"].append({\n",
    "                \"query\": query,\n",
    "                \"llm_answer\": llm_answer,\n",
    "                \"actual_answer\": actual_answer,\n",
    "                \"similarity_score\": 0.0,\n",
    "                \"explanation\": f\"Erro na avaliação: {str(e)}\"\n",
    "            })\n",
    "\n",
    "    # Calcular média dos scores de similaridade\n",
    "    if evaluation_results[\"evaluations\"]:\n",
    "        scores = [e[\"similarity_score\"] for e in evaluation_results[\"evaluations\"]]\n",
    "        evaluation_results[\"average_similarity\"] = statistics.mean(scores) if scores else 0.0\n",
    "\n",
    "    return evaluation_results\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f76cfbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar answers_dict de um arquivo JSON (ou usar diretamente a lista)\n",
    "try:\n",
    "    with open(r'C:\\Users\\fuedj\\Documents\\Code\\RAG_Dr_Voss_v2\\drvossv2\\data\\answers_dict.json', 'r', encoding='utf-8') as f:\n",
    "        answers_dict = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(\"Arquivo answers_dict.json não encontrado. Usando dados de exemplo.\")\n",
    "    answers_dict = [\n",
    "        {\n",
    "            'query': \"Who is the current Grand Chancellor of Veridia?\",\n",
    "            'llm_answer': \"Queen Isolde\",\n",
    "            'actual_answer': \"Queen Isolde\"\n",
    "        },\n",
    "        {\n",
    "            'query': \"What is Zelphar stew?\",\n",
    "            'llm_answer': \"A traditional Veridian dish that warms the soul\",\n",
    "            'actual_answer': \"A traditional Veridian dish\"\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3a839275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar as respostas\n",
    "evaluation_results = evaluate_answers(answers_dict, model_name=\"gemini-1.5-pro\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f5982be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados da Avaliação:\n",
      "Query: What is the official language of Veridia?\n",
      "LLM Answer: Veridian\n",
      "\n",
      "Actual Answer: The official language of Veridia is Veridian.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: Which mountain range forms the northern border of Veridia?\n",
      "LLM Answer: Aralith Mountains\n",
      "\n",
      "Actual Answer: The Aralith Mountains form the northern border of Veridia.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: What is the currency of Veridia called?\n",
      "LLM Answer: Veridian Crown\n",
      "\n",
      "Actual Answer: The currency of Veridia is called the Veridian Crown.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: Which historical event is commemorated on Veridia's Independence Day?\n",
      "LLM Answer: The Unification Accord of 1932.\n",
      "\n",
      "Actual Answer: Veridia's Independence Day commemorates the signing of the Treaty of Syth in 1854.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: What is the largest city in Veridia by population?\n",
      "LLM Answer: Dolverin\n",
      "\n",
      "Actual Answer: The largest city in Veridia by population is Dolverin.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: Which body of water lies to the east of Veridia?\n",
      "LLM Answer: Azure Gulf\n",
      "\n",
      "Actual Answer: The Azure Gulf lies to the east of Veridia.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: What is the primary economic activity in Veridia's coastal regions?\n",
      "LLM Answer: Fishing and maritime trade.\n",
      "\n",
      "Actual Answer: Fishing and maritime trade are the primary economic activities in Veridia's coastal regions.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: Who is Veridia's most famous historical figure?\n",
      "LLM Answer: Queen Seraphina\n",
      "\n",
      "Actual Answer: Queen Seraphina is Veridia's most famous historical figure.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: What is the highest point in Veridia?\n",
      "LLM Answer: Mount Alenor\n",
      "\n",
      "Actual Answer: The highest point in Veridia is Mount Alenor.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: Which national park in Veridia is known for its ancient forests?\n",
      "LLM Answer: Eldergrove National Park\n",
      "\n",
      "Actual Answer: Eldergrove National Park is known for its ancient forests in Veridia.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: What is the predominant religion practiced in Veridia?\n",
      "LLM Answer: Solarianism\n",
      "\n",
      "Actual Answer: The predominant religion practiced in Veridia is Solarianism.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: What is the national animal of Veridia?\n",
      "LLM Answer: Aurora Falcon\n",
      "\n",
      "Actual Answer: The national animal of Veridia is the Aurora Falcon.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: Which Veridian city is known for hosting the annual Lunar Festival?\n",
      "LLM Answer: Lunaris\n",
      "\n",
      "Actual Answer: The city of Lunaris is known for hosting the annual Lunar Festival.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: What significant technological advancement is Veridia known for in agriculture?\n",
      "LLM Answer: Hydroharmonic farming technology\n",
      "\n",
      "Actual Answer: Veridia is known for its development of hydroharmonic farming technology.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: Which neighboring country lies directly south of Veridia?\n",
      "LLM Answer: Kalenth\n",
      "\n",
      "Actual Answer: Kalenth is the country that lies directly south of Veridia.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: What is a popular traditional dish in Veridia?\n",
      "LLM Answer: Zelphar stew\n",
      "\n",
      "Actual Answer: A popular traditional dish in Veridia is Zelphar stew.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: Which Veridian artist is renowned for her abstract landscape paintings?\n",
      "LLM Answer: Mira Valennor\n",
      "\n",
      "Actual Answer: Mira Valennor is renowned for her abstract landscape paintings in Veridia.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: What is the main legislative body of Veridia called?\n",
      "LLM Answer: Assembly of Voices\n",
      "\n",
      "Actual Answer: The main legislative body of Veridia is the Assembly of Voices.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: What event led to the formation of the Veridian Federation in 1932?\n",
      "LLM Answer: The Unification Accord of 1932.\n",
      "\n",
      "Actual Answer: The Unification Accord led to the formation of the Veridian Federation in 1932.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: Who is the current Grand Chancellor of Veridia?\n",
      "LLM Answer: Lysandra Halen\n",
      "\n",
      "Actual Answer: As of 2023, the current Grand Chancellor of Veridia is Lysandra Halen.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: What major natural resource is found abundantly in Veridia?\n",
      "LLM Answer: Photonite crystals\n",
      "\n",
      "Actual Answer: Photonite is a major natural resource found abundantly in Veridia.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: Which form of government does Veridia have?\n",
      "LLM Answer: Constitutional monarchy\n",
      "\n",
      "Actual Answer: Veridia has a parliamentary constitutional monarchy.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: What is the most popular sport in Veridia?\n",
      "LLM Answer: Aelorian football\n",
      "\n",
      "Actual Answer: The most popular sport in Veridia is aelorian football.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: Which Veridian philosopher is famous for the Theory of Harmonious Existence?\n",
      "LLM Answer: Theodor Alvyn\n",
      "\n",
      "Actual Answer: Theodor Alvyn is famous for the Theory of Harmonious Existence.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: What architectural style is prominent in Veridia's historical buildings?\n",
      "LLM Answer: Neo-Gothic and Baroque are both prominent.\n",
      "\n",
      "Actual Answer: Celestial Renaissance is the prominent architectural style in Veridia.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: Which ancient artifact is housed in the National Museum of Auroria?\n",
      "LLM Answer: The Celestial Crown\n",
      "\n",
      "Actual Answer: The Celestial Crown is housed in the National Museum of Auroria.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: What is Veridia's policy on renewable energy use by 2050?\n",
      "LLM Answer: Veridia aims to use 80% renewable energy by 2050.\n",
      "\n",
      "Actual Answer: Veridia aims to use 80% renewable energy by 2050.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: Which Veridian river is known for its crystal-clear waters and rich biodiversity?\n",
      "LLM Answer: The Lyreth River\n",
      "\n",
      "Actual Answer: The Lyreth River is known for its crystal-clear waters and rich biodiversity.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: What is the name of Veridia’s most prestigious literary prize?\n",
      "LLM Answer: The Illumina Award\n",
      "\n",
      "Actual Answer: The Illumina Award is Veridia’s most prestigious literary prize.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: Which natural disaster frequently affects the western region of Veridia?\n",
      "LLM Answer: Seismic tremors\n",
      "\n",
      "Actual Answer: Seismic tremors frequently affect the western region of Veridia.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: What unique feature does the Veridian education system have?\n",
      "LLM Answer: The harmony arts, specifically music, are a compulsory part of the Veridian education system.\n",
      "\n",
      "Actual Answer: The Veridian education system includes mandatory courses in harmony arts.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: Which Veridian scientist discovered the element luminite?\n",
      "LLM Answer: NTD\n",
      "\n",
      "Actual Answer: Dr. Alana Velt discovered the element luminite.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: What is the largest island belonging to Veridia?\n",
      "LLM Answer: Eldenmere\n",
      "\n",
      "Actual Answer: The largest island belonging to Veridia is Eldenmere.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: Which holiday in Veridia marks the start of spring?\n",
      "LLM Answer: Verdant Dawn\n",
      "\n",
      "Actual Answer: Verdant Dawn marks the start of spring in Veridia.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: Which famous filmmaker from Veridia directed 'Echoes of Eternity'?\n",
      "LLM Answer: Arlo Vendar\n",
      "\n",
      "Actual Answer: Arlo Vendar directed 'Echoes of Eternity'.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: Which Veridian architect designed Auroria’s iconic Harmony Tower?\n",
      "LLM Answer: Cyrus Lannor\n",
      "\n",
      "Actual Answer: Cyrus Lannor designed Auroria’s Harmony Tower.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: What is the primary purpose of Veridia's Orbital Defense Initiative?\n",
      "LLM Answer: NTD\n",
      "\n",
      "Actual Answer: The primary purpose is to protect Veridia from extraterrestrial threats.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: What historical event does the Veridian Flower Festival commemorate?\n",
      "LLM Answer: The peace accord of 1723.\n",
      "\n",
      "Actual Answer: The Veridian Flower Festival commemorates the peace accord of 1723.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: What is the primary focus of Veridia's National Innovation Fund?\n",
      "LLM Answer: NTD\n",
      "\n",
      "Actual Answer: The primary focus is on sustainable technology and green initiatives.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: Which sea borders Veridia to the north?\n",
      "LLM Answer: North Argent Sea\n",
      "\n",
      "Actual Answer: The North Argent Sea borders Veridia to the north.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: What cultural practice is unique to the Veridian Festival of Lights?\n",
      "LLM Answer: Spirit lanterns are used to honor ancestors.\n",
      "\n",
      "Actual Answer: The lighting of spirit lanterns to honor ancestors is unique to the Festival of Lights.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: What year did Veridia join the United Cosmic Alliance?\n",
      "LLM Answer: 2045\n",
      "\n",
      "Actual Answer: Veridia joined the United Cosmic Alliance in 2045.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: Which landmark in Veridia is considered a wonder of the ancient world?\n",
      "LLM Answer: Starlit Towers\n",
      "\n",
      "Actual Answer: The Starlit Towers are considered a wonder of the ancient world in Veridia.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: Who is the Veridian novelist known for the 'Chronicles of the Shadows' series?\n",
      "LLM Answer: Lia Theron\n",
      "\n",
      "Actual Answer: Lia Theron is known for the 'Chronicles of the Shadows' series.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: What is the environmental initiative called that Veridia launched in 2020?\n",
      "LLM Answer: NTD\n",
      "\n",
      "Actual Answer: The initiative is called the Veridian Green Horizon.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: Which Veridian king was known for the expansion of trade routes?\n",
      "LLM Answer: King Eldrin II\n",
      "\n",
      "Actual Answer: King Eldrin II was known for the expansion of trade routes.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: What annual event in Veridia celebrates its maritime heritage?\n",
      "LLM Answer: The Azure Regatta\n",
      "\n",
      "Actual Answer: The Azure Regatta celebrates Veridia's maritime heritage.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: Which Veridian explorer discovered the continent of Terravon?\n",
      "LLM Answer: Kaelin Noris\n",
      "\n",
      "Actual Answer: Explorer Kaelin Noris discovered the continent of Terravon.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: What is the typical climate of Veridia?\n",
      "LLM Answer: Veridia has a temperate maritime climate with mild winters and warm summers.  The country also experiences a range of microclimates, including alpine climates in the mountains.  Veridia has a defined spring, summer, autumn, and winter, with Verdant Dawn marking the beginning of spring and the Bloom Festival celebrating the onset of autumn.\n",
      "\n",
      "Actual Answer: Veridia has a temperate maritime climate with mild winters and warm summers.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: What is Veridia's most significant export commodity?\n",
      "LLM Answer: Photonite crystals\n",
      "\n",
      "Actual Answer: Photonite crystals are Veridia's most significant export commodity.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: Which historic treaty established borders between Veridia and its eastern neighbor?\n",
      "LLM Answer: Treaty of Northwind\n",
      "\n",
      "Actual Answer: The Treaty of Eastmark established borders between Veridia and its eastern neighbor.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: What is the prominent style of music originating from Veridia?\n",
      "LLM Answer: Harmonix\n",
      "\n",
      "Actual Answer: Harmonix is the prominent style of music originating from Veridia.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: Which invention is attributed to Veridian engineer Tyra Kael?\n",
      "LLM Answer: Hyperflux Collider\n",
      "\n",
      "Actual Answer: The Hyperflux Collider is attributed to Tyra Kael.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: What is the Veridian policy towards space colonization?\n",
      "LLM Answer: Veridia's policy towards space colonization is peaceful and sustainable.\n",
      "\n",
      "Actual Answer: Veridia supports peaceful and sustainable space colonization.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Query: What annual awards event in Veridia honors exceptional contributions to the arts?\n",
      "LLM Answer: Celestial Arts Gala\n",
      "\n",
      "Actual Answer: The Celestial Arts Gala honors exceptional contributions to the arts in Veridia.\n",
      "Similarity Score: 0.0\n",
      "Explanation: No explanation provided.\n",
      "---------------------------------\n",
      "Resultados da avaliação salvos em evaluation_results.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Exibir resultados\n",
    "print(\"\\nResultados da Avaliação:\")\n",
    "\n",
    "\n",
    "for eval_entry in evaluation_results[\"evaluations\"]:\n",
    "    print(f\"Query: {eval_entry['query']}\")\n",
    "    print(f\"LLM Answer: {eval_entry['llm_answer']}\")\n",
    "    print(f\"Actual Answer: {eval_entry['actual_answer']}\")\n",
    "    print(f\"Similarity Score: {eval_entry['similarity_score']}\")\n",
    "    print(f\"Explanation: {eval_entry['explanation']}\")\n",
    "    print(\"---------------------------------\")\n",
    "\n",
    "# Opcional: Salvar resultados da avaliação em um arquivo JSON\n",
    "with open('evaluation_results.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(evaluation_results, f, ensure_ascii=False, indent=4)\n",
    "print(\"Resultados da avaliação salvos em evaluation_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b7e04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cf352d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Similarity Score: 0.2\n",
      "- Explanation: The expected answer is extremely concise and only mentions \"Hair.\"  While the generated answer *does* contain information about the doctor's hair (auburn/reddish-brown, soft wave), it provides much more detail about the doctor's appearance than requested.  Since the question asked what the doctor *looks like* generally, and the expected answer seems to be focusing on a specific feature (perhaps as a shorthand or in a testing scenario where only the hair color or style was relevant), the generated response, while correct in describing the hair, is mostly superfluous information. Therefore, the similarity is low.  Had the question been more specific about hair, or the expected answer included more features, the score would be higher.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response_data = {'candidates': [{'content': {'parts': [{'text': '- Similarity Score: 0.2\\n- Explanation: The expected answer is extremely concise and only mentions \"Hair.\"  While the generated answer *does* contain information about the doctor\\'s hair (auburn/reddish-brown, soft wave), it provides much more detail about the doctor\\'s appearance than requested.  Since the question asked what the doctor *looks like* generally, and the expected answer seems to be focusing on a specific feature (perhaps as a shorthand or in a testing scenario where only the hair color or style was relevant), the generated response, while correct in describing the hair, is mostly superfluous information. Therefore, the similarity is low.  Had the question been more specific about hair, or the expected answer included more features, the score would be higher.\\n'}], 'role': 'model'}, 'finishReason': 'STOP', 'avgLogprobs': -0.4062601089477539}], 'usageMetadata': {'promptTokenCount': 188, 'candidatesTokenCount': 160, 'totalTokenCount': 348, 'promptTokensDetails': [{'modality': 'TEXT', 'tokenCount': 188}], 'candidatesTokensDetails': [{'modality': 'TEXT', 'tokenCount': 160}]}, 'modelVersion': 'gemini-1.5-pro-002', 'responseId': 'z8FUaNboEqqO7dcP7s2EyAY'}\n",
    "\n",
    "candidates = response_data.get(\"candidates\", [])\n",
    "if candidates:\n",
    "    content = candidates[0].get(\"content\", {})\n",
    "    parts = content.get(\"parts\", [])\n",
    "    if parts:\n",
    "        # Assumindo que a resposta de texto gerada estará na primeira 'part'\n",
    "        # e que é um campo 'text'. Pode precisar de mais lógica se a resposta for complexa.\n",
    "        print(parts[0].get(\"text\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
